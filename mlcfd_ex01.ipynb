{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlcfd_ex01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geonhong/mlcfd/blob/master/mlcfd_ex01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFlEzBXDPY-v",
        "colab_type": "text"
      },
      "source": [
        "## Regression ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLIcf6Tsvzx_",
        "colab_type": "text"
      },
      "source": [
        "## Import Data ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ykn75UyttZAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "787a77af-5c4c-4241-cbe6-4cdc2f833c98"
      },
      "source": [
        "import requests\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#datin = np.load('gdrive/My Drive/Works/mlcfd/volfrac_data.npy')\n",
        "#target = np.load('gdrive/My Drive/Works/mlcfd/volfrac_target.npy')\n",
        "\n",
        "def load_from_url(url):\n",
        "  resp = requests.get(url, stream=True)\n",
        "  \n",
        "  with open('tmp.npy', 'wb') as f:\n",
        "    shutil.copyfileobj(resp.raw, f)\n",
        "   \n",
        "  var = np.load('tmp.npy')\n",
        "  \n",
        "  return var\n",
        "\n",
        "datin = load_from_url('https://github.com/geonhong/mlcfd/blob/master/volfrac/samples/volfrac_data.npy?raw=true')\n",
        "target = load_from_url('https://github.com/geonhong/mlcfd/blob/master/volfrac/samples/volfrac_target.npy?raw=true')\n",
        "\n",
        "print(datin.shape)\n",
        "print(target.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(122, 64)\n",
            "(122,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voLmWyhvv2Ar",
        "colab_type": "text"
      },
      "source": [
        "## Build model ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx471Q0iv55P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "40e5e1fe-1c46-4b46-8984-89da80d06ba8"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "def build_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(16, activation='relu', input_shape=(datin.shape[1],)))\n",
        "  model.add(layers.Dense(16, activation='relu', input_shape=(datin.shape[1],)))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "model = build_model()\n",
        "# model.fit(datin, target, epochs=num_epochs, batch_size=1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0620 10:19:20.054272 139691811927936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0620 10:19:20.096915 139691811927936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0620 10:19:20.108005 139691811927936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0620 10:19:20.150928 139691811927936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIIk_LDOx_2r",
        "colab_type": "text"
      },
      "source": [
        "Load a diamond volume fraction and predict the result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BETdA-MvwZKQ",
        "colab_type": "text"
      },
      "source": [
        "### Manipulate data input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMSjwiHbwX6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e73d1008-24cc-41ad-b3c0-09f8afd7866f"
      },
      "source": [
        "dataset = datin\n",
        "targets = target\n",
        "\n",
        "print(dataset.shape)\n",
        "print(targets.shape)\n",
        "\n",
        "# Shuffle data\n",
        "index = np.arange(len(dataset))\n",
        "np.random.shuffle(index)\n",
        "\n",
        "train_data = []\n",
        "train_targ = []\n",
        "\n",
        "test_data = []\n",
        "test_targ = []\n",
        "\n",
        "i = 0\n",
        "for itrg in index:\n",
        "  if i<100:\n",
        "    train_data.append(dataset[itrg])\n",
        "    train_targ.append(targets[itrg])\n",
        "  else:\n",
        "    test_data.append(dataset[itrg])\n",
        "    test_targ.append(targets[itrg])\n",
        "\n",
        "  i += 1\n",
        "\n",
        "train_data = np.array(train_data)\n",
        "train_targ = np.array(train_targ)\n",
        "\n",
        "test_data = np.array(test_data)\n",
        "test_targ = np.array(test_targ)\n",
        "    \n",
        "print(\"train data shape: \", train_data.shape)\n",
        "print(\"train target shape: \", train_targ.shape)\n",
        "print(\"test data shape: \", test_data.shape)\n",
        "print(\"test target shape: \", test_targ.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(122, 64)\n",
            "(122,)\n",
            "train data shape:  (100, 64)\n",
            "train target shape:  (100,)\n",
            "test data shape:  (22, 64)\n",
            "test target shape:  (22,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n-koD12XpCH",
        "colab_type": "text"
      },
      "source": [
        "### Build a model and evaluate the results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw2IOvSHX38G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "c825ed22-884d-4071-89bc-98e62ed64ac3"
      },
      "source": [
        "num_epochs = 20\n",
        "\n",
        "model.fit(train_data, train_targ, epochs=num_epochs, batch_size=1)\n",
        "\n",
        "val_mse, val_mae = model.evaluate(test_data, test_targ)\n",
        "\n",
        "print(\"MSE: \", val_mse)\n",
        "print(\"MAE: \", val_mae)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6260 - mean_absolute_error: 0.6299\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1551 - mean_absolute_error: 0.3187\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0707 - mean_absolute_error: 0.2045\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0649 - mean_absolute_error: 0.1944\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0537 - mean_absolute_error: 0.1692\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0424 - mean_absolute_error: 0.1613\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0356 - mean_absolute_error: 0.1412\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0309 - mean_absolute_error: 0.1217\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0265 - mean_absolute_error: 0.1114\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0251 - mean_absolute_error: 0.1111\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0226 - mean_absolute_error: 0.1121\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0186 - mean_absolute_error: 0.1026\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0162 - mean_absolute_error: 0.0891\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0155 - mean_absolute_error: 0.0889\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0146 - mean_absolute_error: 0.0882\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0130 - mean_absolute_error: 0.0841\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0132 - mean_absolute_error: 0.0824\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0141 - mean_absolute_error: 0.0829\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0130 - mean_absolute_error: 0.0846\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0127 - mean_absolute_error: 0.0780\n",
            "22/22 [==============================] - 0s 2ms/step\n",
            "MSE:  0.03931015357375145\n",
            "MAE:  0.16189011931419373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Iq4ru-NZWM-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ab59bf27-8f2b-40eb-85aa-f8355188e27b"
      },
      "source": [
        "i = 0\n",
        "\n",
        "cd_pred = model.predict(test_data)\n",
        "\n",
        "for i in range(0, len(cd_pred)):\n",
        "  \n",
        "  diff = float(test_targ[i]) - float(cd_pred[i])\n",
        "  err = diff/float(test_targ[i])\n",
        "  \n",
        "  print(i, test_targ[i], float(cd_pred[i]), diff, err)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1.9363976264032607 1.9681545495986938 -0.03175692319543311 -0.016400001096066014\n",
            "1 0.9152300797205262 0.9999894499778748 -0.08475937025734859 -0.09260990447694926\n",
            "2 1.8709652016968163 1.810355305671692 0.060609896025124455 0.03239498841034355\n",
            "3 2.18026754497884 2.407454013824463 -0.22718646884562288 -0.10420118822978112\n",
            "4 2.5750032470757622 2.7005088329315186 -0.12550558585575633 -0.04873997188092232\n",
            "5 2.2499093918537754 2.8095333576202393 -0.5596239657664639 -0.24873177906305421\n",
            "6 1.8765877319897402 2.0136735439300537 -0.13708581194031355 -0.07305057451002404\n",
            "7 0.6141546786888715 0.7912402153015137 -0.17708553661264215 -0.2883402874837546\n",
            "8 2.4979940772720965 2.668829917907715 -0.1708358406356183 -0.0683892096422332\n",
            "9 2.6297066112219447 2.745307683944702 -0.11560107272275744 -0.04395968441096976\n",
            "10 0.5768186547945997 0.7597330808639526 -0.18291442606935293 -0.3171090680735477\n",
            "11 0.2126918943935795 0.30715614557266235 -0.09446425117908286 -0.4441365828651646\n",
            "12 2.1133330774668684 2.5126495361328125 -0.3993164586659441 -0.18895102855465734\n",
            "13 1.839515184051775 1.9520728588104248 -0.11255767475864986 -0.06118877176687758\n",
            "14 0.247964152281062 0.35972630977630615 -0.11176215749524415 -0.4507190110631966\n",
            "15 2.379730178986804 2.6135456562042236 -0.2338154772174197 -0.09825293610260016\n",
            "16 0.703356054598871 0.8731587529182434 -0.16980269831937245 -0.24141783838942305\n",
            "17 1.9884809442297033 2.0753214359283447 -0.08684049169864139 -0.04367177465322988\n",
            "18 1.377063655253608 1.4960730075836182 -0.1190093523300102 -0.08642254980441899\n",
            "19 0.6561071990618423 0.8283547759056091 -0.1722475768437668 -0.26252962486932163\n",
            "20 2.262182139454679 2.353553056716919 -0.09137091726223989 -0.04039061031764035\n",
            "21 1.1009129535718778 1.1983424425125122 -0.09742948894063441 -0.08849881239432007\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}